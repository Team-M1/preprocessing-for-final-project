{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "\r\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 데이터 불러오기\r\n",
    "\r\n",
    "df = pd.read_csv(\"./data/혐오표현_정제.csv\")\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content  hate  gender_hate\n",
       "0                  걍 이 병신나라 민도가 좆박은건데 어쩔수가 잇나 걍 망해야지     1            0\n",
       "1               그 앰생 쓰레기 병신들은 짐승이고. 니는 짐승을 사람 취급해주냐.     1            0\n",
       "2                                제발 너그집으로 꺼져 애미뒤진새끼야     1            0\n",
       "3                                      몸만지면 대주는 걸레년임     1            1\n",
       "4  환경오염도 이쯤되면 심각하고 자식 낳아봐야 지들 애미애비(그러므로 너 나 우리)가 ...     1            0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>hate</th>\n",
       "      <th>gender_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>걍 이 병신나라 민도가 좆박은건데 어쩔수가 잇나 걍 망해야지</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그 앰생 쓰레기 병신들은 짐승이고. 니는 짐승을 사람 취급해주냐.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>제발 너그집으로 꺼져 애미뒤진새끼야</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>몸만지면 대주는 걸레년임</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>환경오염도 이쯤되면 심각하고 자식 낳아봐야 지들 애미애비(그러므로 너 나 우리)가 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 만약 클래스별 가중치를 구하겠다면 사용\r\n",
    "\r\n",
    "# weight = df.shape[0] / (len(df[\"gender_hate\"].unique()) * np.bincount(df[\"gender_hate\"]))\r\n",
    "# weight = torch.from_numpy(weight).float()\r\n",
    "# weight"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5651, 4.3406])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 모델 불러오기\r\n",
    "\r\n",
    "from transformers import ElectraForSequenceClassification, ElectraTokenizer\r\n",
    "from tokenization_kocharelectra import KoCharElectraTokenizer\r\n",
    "\r\n",
    "\r\n",
    "electramodel = ElectraForSequenceClassification.from_pretrained(\"monologg/kocharelectra-small-discriminator\")\r\n",
    "tokenizer = KoCharElectraTokenizer.from_pretrained(\"monologg/kocharelectra-small-discriminator\")\r\n",
    "electramodel = electramodel.to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at monologg/kocharelectra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/kocharelectra-small-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
      "The class this function is called from is 'KoCharElectraTokenizer'.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 데이터프레임을 TensorDataset으로 만들기\r\n",
    "\r\n",
    "from torch.utils.data import TensorDataset\r\n",
    "\r\n",
    "from data_preprocess import df_to_feature_and_label\r\n",
    "\r\n",
    "\r\n",
    "all_data = TensorDataset(*df_to_feature_and_label(df, tokenizer, max_length=256))\r\n",
    "\r\n",
    "lr = 0.001\r\n",
    "\r\n",
    "# criterion = torch.nn.CrossEntropyLoss(weight=weight.to(device))  # 클래스별 가중치가 적용된 크로스엔트로피로스\r\n",
    "criterion = torch.nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(electramodel.classifier.parameters(), lr=lr)\r\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# ImbalancedDatasetSampler에서 사용되는 함수\r\n",
    "# dataset[:][3]은 label값을 가리킨다.\r\n",
    "\r\n",
    "def get_labels(dataset):\r\n",
    "    return dataset[:][3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tqdm.notebook import tqdm, trange\r\n",
    "\r\n",
    "\r\n",
    "def train(dataloader, model, criterion, optimizer, scheduler=None):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    num_batches = len(dataloader)\r\n",
    "\r\n",
    "    with tqdm(total=num_batches, desc=\"train\") as progressbar:\r\n",
    "        for batch, (ids, mask, tti, label) in enumerate(dataloader):\r\n",
    "            ids, mask, tti, label = ids.to(device), mask.to(device), tti.to(device), label.to(device)\r\n",
    "\r\n",
    "            pred = model(input_ids=ids, attention_mask=mask, token_type_ids=tti)\r\n",
    "            logits = pred.logits.to(device)\r\n",
    "            loss = criterion(logits.view(-1, 2), label.view(-1))\r\n",
    "\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            if scheduler is not None:\r\n",
    "                scheduler.step()\r\n",
    "\r\n",
    "            if batch % 20 == 0:\r\n",
    "                loss_, current = loss.item(), batch * len(ids)\r\n",
    "                print(f\"loss: {loss_:>7f} [{current:>5d}/{size:>5d}]\")\r\n",
    "\r\n",
    "            progressbar.update(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def test(dataloader, model, criterion):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    num_batches = len(dataloader)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "\r\n",
    "    with torch.no_grad(), tqdm(total=num_batches, desc=\"test\") as progressbar:\r\n",
    "        for ids, mask, tti, label in dataloader:\r\n",
    "            ids, mask, tti, label = ids.to(device), mask.to(device), tti.to(device), label.to(device)\r\n",
    "\r\n",
    "            pred = model(input_ids=ids, attention_mask=mask, token_type_ids=tti)\r\n",
    "            logits = pred.logits.to(device)\r\n",
    "            loss = criterion(logits.view(-1, 2), label.view(-1))\r\n",
    "\r\n",
    "            test_loss += loss\r\n",
    "            correct += (pred.logits.argmax(1) == label).type(torch.float).sum().item()\r\n",
    "\r\n",
    "            progressbar.update(1)\r\n",
    "\r\n",
    "    test_loss /= num_batches\r\n",
    "    correct /= size\r\n",
    "    print(f\"Test Error:\\n Accuracy: {100 * correct:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from datetime import datetime\r\n",
    "\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from torch.utils.data import Subset, DataLoader\r\n",
    "\r\n",
    "from torchsampler import ImbalancedDatasetSampler\r\n",
    "\r\n",
    "\r\n",
    "def training(dataset, model, criterion, optimizer, epochs, scheduler=None, cv=5, batch_size=64):\r\n",
    "    for epoch in trange(1, epochs + 1, desc=\"Epoch\"):\r\n",
    "        print(f\"Epoch {epoch}\\n------------------------------------------\")\r\n",
    "        kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\r\n",
    "\r\n",
    "        for train_idx, val_idx in kfold.split(dataset[:][0], dataset[:][3]):\r\n",
    "            train_data = Subset(dataset, train_idx)\r\n",
    "            val_data = Subset(dataset, val_idx)\r\n",
    "\r\n",
    "            train_loader = DataLoader(\r\n",
    "                train_data,\r\n",
    "                batch_size=batch_size,\r\n",
    "                sampler=ImbalancedDatasetSampler(train_data, callback_get_label=get_labels))\r\n",
    "            val_loader = DataLoader(\r\n",
    "                val_data,\r\n",
    "                batch_size=batch_size,\r\n",
    "                sampler=ImbalancedDatasetSampler(val_data, callback_get_label=get_labels))\r\n",
    "\r\n",
    "            train(train_loader, model, criterion, optimizer, scheduler)\r\n",
    "            test(val_loader, model, criterion)\r\n",
    "\r\n",
    "    t = datetime.now()\r\n",
    "    today = f\"{t.year % 100}{t.month:02}{t.day:02}\"\r\n",
    "    file_name = f\"model{today}.pth\"\r\n",
    "\r\n",
    "    print(\"완료\")\r\n",
    "    torch.save(model.state_dict(), file_name)\r\n",
    "    print(\"모델 저장:\", file_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training(all_data, electramodel, criterion, optimizer, epochs=200, scheduler=scheduler)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "c86e0eb5395ede85b9f59b6e8263bc6c22037c4e880f7255165769e612363282"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}